{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pfam seed random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:27.317500Z",
     "iopub.status.busy": "2021-12-02T20:33:27.317142Z",
     "iopub.status.idle": "2021-12-02T20:33:27.967393Z",
     "shell.execute_reply": "2021-12-02T20:33:27.966465Z",
     "shell.execute_reply.started": "2021-12-02T20:33:27.317442Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:27.969564Z",
     "iopub.status.busy": "2021-12-02T20:33:27.969012Z",
     "iopub.status.idle": "2021-12-02T20:33:27.985172Z",
     "shell.execute_reply": "2021-12-02T20:33:27.984195Z",
     "shell.execute_reply.started": "2021-12-02T20:33:27.969509Z"
    }
   },
   "outputs": [],
   "source": [
    "data_partitions_dirpath = '../input/random_split/random_split'\n",
    "print('Available dataset partitions: ', os.listdir(data_partitions_dirpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:27.987226Z",
     "iopub.status.busy": "2021-12-02T20:33:27.986719Z",
     "iopub.status.idle": "2021-12-02T20:33:43.595623Z",
     "shell.execute_reply": "2021-12-02T20:33:43.594852Z",
     "shell.execute_reply.started": "2021-12-02T20:33:27.987081Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_all_shards(partition='dev', data_dir=data_partitions_dirpath):\n",
    "    shards = []\n",
    "    for fn in os.listdir(os.path.join(data_dir, partition)):\n",
    "        with open(os.path.join(data_dir, partition, fn)) as f:\n",
    "            shards.append(pd.read_csv(f, index_col=None))\n",
    "    return pd.concat(shards)\n",
    "\n",
    "test = read_all_shards('test')\n",
    "dev = read_all_shards('dev')\n",
    "train = read_all_shards('train')\n",
    "\n",
    "partitions = {'test': test, 'dev': dev, 'train': train}\n",
    "for name, df in partitions.items():\n",
    "    print('Dataset partition \"%s\" has %d sequences' % (name, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:43.597288Z",
     "iopub.status.busy": "2021-12-02T20:33:43.597017Z",
     "iopub.status.idle": "2021-12-02T20:33:43.602409Z",
     "shell.execute_reply": "2021-12-02T20:33:43.601669Z",
     "shell.execute_reply.started": "2021-12-02T20:33:43.597233Z"
    }
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True, drop=True)\n",
    "dev.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### quick look at the most common families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:43.604153Z",
     "iopub.status.busy": "2021-12-02T20:33:43.603626Z",
     "iopub.status.idle": "2021-12-02T20:33:43.795600Z",
     "shell.execute_reply": "2021-12-02T20:33:43.794760Z",
     "shell.execute_reply.started": "2021-12-02T20:33:43.604100Z"
    }
   },
   "outputs": [],
   "source": [
    "train.groupby('family_id').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:43.797101Z",
     "iopub.status.busy": "2021-12-02T20:33:43.796835Z",
     "iopub.status.idle": "2021-12-02T20:33:43.802694Z",
     "shell.execute_reply": "2021-12-02T20:33:43.801455Z",
     "shell.execute_reply.started": "2021-12-02T20:33:43.797054Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTransitionMatForSequence(transitions, default):\n",
    "    df = pd.DataFrame(transitions)\n",
    "    df['shift'] = df[0].shift(-1)\n",
    "    df['count'] = 1\n",
    "    trans_mat = df.groupby([0, 'shift']).count().unstack().fillna(0)\n",
    "    trans_mat.columns = trans_mat.columns.droplevel()\n",
    "    return (default+trans_mat).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:43.804744Z",
     "iopub.status.busy": "2021-12-02T20:33:43.804250Z",
     "iopub.status.idle": "2021-12-02T20:33:43.813644Z",
     "shell.execute_reply": "2021-12-02T20:33:43.812871Z",
     "shell.execute_reply.started": "2021-12-02T20:33:43.804559Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeHeatmap(df, familyId):\n",
    "    mask = df.family_id == familyId\n",
    "    famSeqs = df.loc[mask, 'sequence'].reset_index(drop=True)\n",
    "    AAs = [aa for aa in 'GALMFWKQESPVICYHRNDTXUBOZ']\n",
    "    seqs = famSeqs.apply(lambda seq: [aa for aa in seq])\n",
    "    default = pd.DataFrame([[0]*len(AAs)]*len(AAs), columns=AAs, index=AAs, dtype='int64')\n",
    "    transMat = default.copy()\n",
    "    for seq in seqs: #tqdm(seqs):\n",
    "        transMat += getTransitionMatForSequence(seq, default)\n",
    "    maskX = transMat.sum(axis=1) != 0\n",
    "    maskY = transMat.sum(axis=0) != 0\n",
    "    transMat = transMat.loc[maskX, maskY]\n",
    "    transMat = transMat.div(transMat.sum(axis=1), axis=0)\n",
    "    return transMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this is how the transition matrix heatmap looks like for the Methyltransf_25 family from the dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:43.816039Z",
     "iopub.status.busy": "2021-12-02T20:33:43.815437Z",
     "iopub.status.idle": "2021-12-02T20:33:48.073735Z",
     "shell.execute_reply": "2021-12-02T20:33:48.072867Z",
     "shell.execute_reply.started": "2021-12-02T20:33:43.815685Z"
    }
   },
   "outputs": [],
   "source": [
    "seaborn.heatmap(makeHeatmap(dev, 'Methyltransf_25'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### and for the Lipase_GDSL_2 family from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:48.075508Z",
     "iopub.status.busy": "2021-12-02T20:33:48.075050Z",
     "iopub.status.idle": "2021-12-02T20:33:59.202001Z",
     "shell.execute_reply": "2021-12-02T20:33:59.201226Z",
     "shell.execute_reply.started": "2021-12-02T20:33:48.075455Z"
    }
   },
   "outputs": [],
   "source": [
    "seaborn.heatmap(makeHeatmap(train, 'Lipase_GDSL_2'), vmax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we should be able to observe a quite distinctive heatmap for each family, although families have been created using more sophisticated methods than can markov chains; they were created using profile HMMs, which models insertions and deletions and are based off the multiple sequence alignment. However, note that Pfam is not as simple as running HMMSearch on a seed sequence: \"Pfam entries are manually annotated with functional information from the literature where available.\"\n",
    "Pfam: The protein families database in 2021: J. Mistry, S. Chuguransky, L. Williams, M. Qureshi, G.A. Salazar, E.L.L. Sonnhammer, S.C.E. Tosatto, L. Paladin, S. Raj, L.J. Richardson, R.D. Finn, A. Bateman\n",
    "Nucleic Acids Research (2020) doi: 10.1093/nar/gkaa913"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### based on the above, the best method to classify families is likely to be profile HMMs ... however, it is more interesting to create a deep learning model from scratch than running HMMER ... it is also possible for a deep learning model to surpass HMMER actually on Pfam! This was shown by Google research: \n",
    "Using Deep Learning to Annotate the Protein Universe\n",
    "Maxwell L. Bileschi, David Belanger, Drew Bryant, Theo Sanderson, Brandon Carter, D. Sculley, Mark A. DePristo, Lucy J. Colwell\n",
    "bioRxiv 626507; doi: https://doi.org/10.1101/626507"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's check out the number of samples in each family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:33:59.203624Z",
     "iopub.status.busy": "2021-12-02T20:33:59.203200Z",
     "iopub.status.idle": "2021-12-02T20:34:00.769704Z",
     "shell.execute_reply": "2021-12-02T20:34:00.768979Z",
     "shell.execute_reply.started": "2021-12-02T20:33:59.203572Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, partition in partitions.items():\n",
    "    partition.groupby('family_id').size().hist(bins=100)\n",
    "    plt.title('Distribution of minority family sizes for %s' % name)\n",
    "    plt.ylabel('# Families')\n",
    "    plt.xlabel('Family size')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zooming in a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:00.771334Z",
     "iopub.status.busy": "2021-12-02T20:34:00.770912Z",
     "iopub.status.idle": "2021-12-02T20:34:01.190198Z",
     "shell.execute_reply": "2021-12-02T20:34:01.189433Z",
     "shell.execute_reply.started": "2021-12-02T20:34:00.771284Z"
    }
   },
   "outputs": [],
   "source": [
    "train.groupby('family_id').size().hist(bins=[1,5,10,20,30,40,50])\n",
    "plt.title('Distribution of minority family sizes for train')\n",
    "plt.ylabel('# Families')\n",
    "plt.xlabel('Family size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:01.191826Z",
     "iopub.status.busy": "2021-12-02T20:34:01.191401Z",
     "iopub.status.idle": "2021-12-02T20:34:01.604829Z",
     "shell.execute_reply": "2021-12-02T20:34:01.604086Z",
     "shell.execute_reply.started": "2021-12-02T20:34:01.191777Z"
    }
   },
   "outputs": [],
   "source": [
    "train.groupby('family_id').size().hist(bins=[100,120,150,175,200,300,400,500,750,1000])\n",
    "plt.title('Distribution of majority family sizes for train')\n",
    "plt.ylabel('# Families')\n",
    "plt.xlabel('Family size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's check the sequence length in the training/dev/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:01.606488Z",
     "iopub.status.busy": "2021-12-02T20:34:01.606048Z",
     "iopub.status.idle": "2021-12-02T20:34:01.616922Z",
     "shell.execute_reply": "2021-12-02T20:34:01.616150Z",
     "shell.execute_reply.started": "2021-12-02T20:34:01.606438Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeSeqLenPlots(familyId=None):\n",
    "    if familyId != None:\n",
    "        famSeqsTrain = train.loc[train.family_id == familyId, 'sequence'].reset_index(drop=True)\n",
    "        famSeqsDev = dev.loc[dev.family_id == familyId, 'sequence'].reset_index(drop=True)\n",
    "        famSeqsTest = test.loc[test.family_id == familyId, 'sequence'].reset_index(drop=True)\n",
    "    else:\n",
    "        famSeqsTrain = train['sequence']\n",
    "        famSeqsDev = dev['sequence']\n",
    "        famSeqsTest = test['sequence']\n",
    "    # Length of sequence in train data for specific family (optional).\n",
    "    trainCharCount = famSeqsTrain.apply(len)\n",
    "    devCharCount = famSeqsDev.apply(len)\n",
    "    testCharCount = famSeqsTest.apply(len)\n",
    "\n",
    "    def plot_seq_count(count, data_name):\n",
    "        seaborn.distplot(count.values)\n",
    "        plt.title(f'Sequence char count: {data_name}')\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plot_seq_count(trainCharCount, 'Train')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plot_seq_count(devCharCount, 'Dev')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plot_seq_count(testCharCount, 'Test')\n",
    "\n",
    "    plt.subplots_adjust(right=3.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:01.624572Z",
     "iopub.status.busy": "2021-12-02T20:34:01.621405Z",
     "iopub.status.idle": "2021-12-02T20:34:03.637510Z",
     "shell.execute_reply": "2021-12-02T20:34:03.636559Z",
     "shell.execute_reply.started": "2021-12-02T20:34:01.624509Z"
    }
   },
   "outputs": [],
   "source": [
    "makeSeqLenPlots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ... and we can also use this function to see the sequence lengths in a specific family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:03.639653Z",
     "iopub.status.busy": "2021-12-02T20:34:03.639084Z",
     "iopub.status.idle": "2021-12-02T20:34:04.641708Z",
     "shell.execute_reply": "2021-12-02T20:34:04.640872Z",
     "shell.execute_reply.started": "2021-12-02T20:34:03.639586Z"
    }
   },
   "outputs": [],
   "source": [
    "makeSeqLenPlots('Acetyltransf_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking families of interest and optional traning size reduction via undersampling\n",
    "- Further analysis to check correspondence between family Id, accession and family version number\n",
    "- Reduced dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version number is unique for each family and family ID is unique for each family accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:04.646980Z",
     "iopub.status.busy": "2021-12-02T20:34:04.646537Z",
     "iopub.status.idle": "2021-12-02T20:34:05.524291Z",
     "shell.execute_reply": "2021-12-02T20:34:05.522768Z",
     "shell.execute_reply.started": "2021-12-02T20:34:04.646807Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train['family_accession'].apply(lambda x: x.split('.')[0]).unique()))\n",
    "print(len(train['family_id'].unique()))\n",
    "print(len(train['family_accession'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of Distinct classes in dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:05.525789Z",
     "iopub.status.busy": "2021-12-02T20:34:05.525489Z",
     "iopub.status.idle": "2021-12-02T20:34:05.541682Z",
     "shell.execute_reply": "2021-12-02T20:34:05.540970Z",
     "shell.execute_reply.started": "2021-12-02T20:34:05.525726Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dev.family_accession.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Not super tricky, i.e. \n",
    "- we have all test/dev labels in train labels\n",
    "- every test/dev family has at least 8 samples in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:05.543499Z",
     "iopub.status.busy": "2021-12-02T20:34:05.543008Z",
     "iopub.status.idle": "2021-12-02T20:34:05.896117Z",
     "shell.execute_reply": "2021-12-02T20:34:05.895471Z",
     "shell.execute_reply.started": "2021-12-02T20:34:05.543452Z"
    }
   },
   "outputs": [],
   "source": [
    "famSize = train.family_accession.value_counts()\n",
    "\n",
    "# Minimum sample size in training set for a class in dev set - all test labels are in train labels\n",
    "famSize.loc[dev.family_accession.unique()].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To be able to run on Kaggle, let's reduce the data by considering the 100 most common families only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:05.897570Z",
     "iopub.status.busy": "2021-12-02T20:34:05.897312Z",
     "iopub.status.idle": "2021-12-02T20:34:06.263180Z",
     "shell.execute_reply": "2021-12-02T20:34:06.262262Z",
     "shell.execute_reply.started": "2021-12-02T20:34:05.897525Z"
    }
   },
   "outputs": [],
   "source": [
    "#taking some families, by default, the 100 most common ones\n",
    "familiesOfInterest = train.family_accession.value_counts()[:100] #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:06.265123Z",
     "iopub.status.busy": "2021-12-02T20:34:06.264584Z",
     "iopub.status.idle": "2021-12-02T20:34:06.427591Z",
     "shell.execute_reply": "2021-12-02T20:34:06.426507Z",
     "shell.execute_reply.started": "2021-12-02T20:34:06.265072Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = train.family_accession.isin(familiesOfInterest.index.values)\n",
    "train = train.loc[mask,:]\n",
    "\n",
    "mask = dev.family_accession.isin(familiesOfInterest.index.values)\n",
    "dev = dev.loc[mask,:]\n",
    "\n",
    "mask = test.family_accession.isin(familiesOfInterest.index.values)\n",
    "test = test.loc[mask,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's check the distribution of the 20 most common families in train/dev/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:06.429483Z",
     "iopub.status.busy": "2021-12-02T20:34:06.429052Z",
     "iopub.status.idle": "2021-12-02T20:34:07.365720Z",
     "shell.execute_reply": "2021-12-02T20:34:07.364839Z",
     "shell.execute_reply.started": "2021-12-02T20:34:06.429426Z"
    }
   },
   "outputs": [],
   "source": [
    "valCounts = pd.concat([pd.DataFrame(train.family_accession.value_counts()[:20]), \n",
    "           pd.DataFrame(dev.family_accession.value_counts()[:20]), \n",
    "           pd.DataFrame(test.family_accession.value_counts()[:20])], \n",
    "          axis=1)\n",
    "valCounts.columns = ['train samples', 'dev samples', 'test samples']\n",
    "valCounts.plot.bar(figsize = (10,7), fontsize = 15, stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's see the histogram of sequence lengths in the reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:07.367769Z",
     "iopub.status.busy": "2021-12-02T20:34:07.367209Z",
     "iopub.status.idle": "2021-12-02T20:34:08.402631Z",
     "shell.execute_reply": "2021-12-02T20:34:08.400972Z",
     "shell.execute_reply.started": "2021-12-02T20:34:07.367703Z"
    }
   },
   "outputs": [],
   "source": [
    "makeSeqLenPlots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final set sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:08.404557Z",
     "iopub.status.busy": "2021-12-02T20:34:08.404133Z",
     "iopub.status.idle": "2021-12-02T20:34:08.409392Z",
     "shell.execute_reply": "2021-12-02T20:34:08.408450Z",
     "shell.execute_reply.started": "2021-12-02T20:34:08.404380Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(dev))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We could have also reduced the data by undersampling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:08.412698Z",
     "iopub.status.busy": "2021-12-02T20:34:08.411796Z",
     "iopub.status.idle": "2021-12-02T20:34:08.420910Z",
     "shell.execute_reply": "2021-12-02T20:34:08.419952Z",
     "shell.execute_reply.started": "2021-12-02T20:34:08.412489Z"
    }
   },
   "outputs": [],
   "source": [
    "# undersampling\n",
    "# train = train.groupby('family_accession').head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's try the BERT embedding from this famous paper:\n",
    "\n",
    "@inproceedings{tape2019,\n",
    "author = {Rao, Roshan and Bhattacharya, Nicholas and Thomas, Neil and Duan, Yan and Chen, Xi and Canny, John and Abbeel, Pieter and Song, Yun S},\n",
    "title = {Evaluating Protein Transfer Learning with TAPE},\n",
    "booktitle = {Advances in Neural Information Processing Systems}\n",
    "year = {2019}\n",
    "}\n",
    "\n",
    "https://github.com/songlab-cal/tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:08.423241Z",
     "iopub.status.busy": "2021-12-02T20:34:08.422903Z",
     "iopub.status.idle": "2021-12-02T20:34:15.706256Z",
     "shell.execute_reply": "2021-12-02T20:34:15.705471Z",
     "shell.execute_reply.started": "2021-12-02T20:34:08.423189Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tape_proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:15.709384Z",
     "iopub.status.busy": "2021-12-02T20:34:15.709083Z",
     "iopub.status.idle": "2021-12-02T20:34:16.722056Z",
     "shell.execute_reply": "2021-12-02T20:34:16.721309Z",
     "shell.execute_reply.started": "2021-12-02T20:34:15.709332Z"
    }
   },
   "outputs": [],
   "source": [
    "from tape import ProteinBertModel, TAPETokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:16.725647Z",
     "iopub.status.busy": "2021-12-02T20:34:16.725411Z",
     "iopub.status.idle": "2021-12-02T20:34:16.770690Z",
     "shell.execute_reply": "2021-12-02T20:34:16.769868Z",
     "shell.execute_reply.started": "2021-12-02T20:34:16.725595Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to half precision for faster speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:16.772706Z",
     "iopub.status.busy": "2021-12-02T20:34:16.772141Z",
     "iopub.status.idle": "2021-12-02T20:34:34.343290Z",
     "shell.execute_reply": "2021-12-02T20:34:34.342377Z",
     "shell.execute_reply.started": "2021-12-02T20:34:16.772649Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ProteinBertModel.from_pretrained('bert-base')\n",
    "modelTAPE = model.to(device)\n",
    "tokenizerTAPE = TAPETokenizer(vocab='iupac')  # iupac is the vocab for TAPE models, use unirep for the UniRep model\n",
    "\n",
    "modelTAPE.half()  # convert to half precision\n",
    "for layer in modelTAPE.modules():\n",
    "    if isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        layer.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's tokenize the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:34.344897Z",
     "iopub.status.busy": "2021-12-02T20:34:34.344580Z",
     "iopub.status.idle": "2021-12-02T20:34:41.533003Z",
     "shell.execute_reply": "2021-12-02T20:34:41.531878Z",
     "shell.execute_reply.started": "2021-12-02T20:34:34.344848Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 25\n",
    "max_length = 512 \n",
    "trunc_type = \"post\"\n",
    "padding_type = \"post\"\n",
    "\n",
    "trainTAPE = [tokenizerTAPE.encode(w.upper()) for w in train['sequence']]\n",
    "valTAPE = [tokenizerTAPE.encode(w.upper()) for w in dev['sequence']]\n",
    "testTAPE = [tokenizerTAPE.encode(w.upper()) for w in test['sequence']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only consider up to the maximum length, set to 512 based off the sequence lengths histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:41.534679Z",
     "iopub.status.busy": "2021-12-02T20:34:41.534386Z",
     "iopub.status.idle": "2021-12-02T20:34:41.977663Z",
     "shell.execute_reply": "2021-12-02T20:34:41.976785Z",
     "shell.execute_reply.started": "2021-12-02T20:34:41.534630Z"
    }
   },
   "outputs": [],
   "source": [
    "trainTAPE = [np.array(t[:max_length]) for t in trainTAPE]\n",
    "valTAPE = [np.array(t[:max_length]) for t in valTAPE]\n",
    "testTAPE = [np.array(t[:max_length]) for t in testTAPE]\n",
    "\n",
    "trainTAPE = [torch.from_numpy(t) for t in trainTAPE]\n",
    "valTAPE = [torch.from_numpy(t) for t in valTAPE]\n",
    "testTAPE = [torch.from_numpy(t) for t in testTAPE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's pad the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:41.979345Z",
     "iopub.status.busy": "2021-12-02T20:34:41.979052Z",
     "iopub.status.idle": "2021-12-02T20:34:43.128558Z",
     "shell.execute_reply": "2021-12-02T20:34:43.127728Z",
     "shell.execute_reply.started": "2021-12-02T20:34:41.979298Z"
    }
   },
   "outputs": [],
   "source": [
    "TAPEtrain = torch.nn.utils.rnn.pad_sequence(trainTAPE, batch_first=False)\n",
    "TAPEvalidation = torch.nn.utils.rnn.pad_sequence(valTAPE, batch_first=False)\n",
    "TAPEtest = torch.nn.utils.rnn.pad_sequence(testTAPE, batch_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Need to transpose to have (sample, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.130106Z",
     "iopub.status.busy": "2021-12-02T20:34:43.129829Z",
     "iopub.status.idle": "2021-12-02T20:34:43.136800Z",
     "shell.execute_reply": "2021-12-02T20:34:43.135884Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.130061Z"
    }
   },
   "outputs": [],
   "source": [
    "TAPEtrain = torch.transpose(TAPEtrain,0,1)\n",
    "TAPEvalidation = torch.transpose(TAPEvalidation,0,1)\n",
    "TAPEtest = torch.transpose(TAPEtest,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.138535Z",
     "iopub.status.busy": "2021-12-02T20:34:43.137981Z",
     "iopub.status.idle": "2021-12-02T20:34:43.149262Z",
     "shell.execute_reply": "2021-12-02T20:34:43.148300Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.138282Z"
    }
   },
   "outputs": [],
   "source": [
    "TAPEvalidation.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define batch sizes and dataloaders to we don't run out of GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.150570Z",
     "iopub.status.busy": "2021-12-02T20:34:43.150318Z",
     "iopub.status.idle": "2021-12-02T20:34:43.158069Z",
     "shell.execute_reply": "2021-12-02T20:34:43.157060Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.150501Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "batch_size = 8 #just reduce the batch size further if GPU is out of memory\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    TAPEtrain,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_validation = DataLoader(\n",
    "    TAPEvalidation,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    TAPEtest,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.160324Z",
     "iopub.status.busy": "2021-12-02T20:34:43.159524Z",
     "iopub.status.idle": "2021-12-02T20:34:43.323638Z",
     "shell.execute_reply": "2021-12-02T20:34:43.322860Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.160270Z"
    }
   },
   "outputs": [],
   "source": [
    "del trainTAPE, valTAPE, TAPEtrain, TAPEvalidation\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.325413Z",
     "iopub.status.busy": "2021-12-02T20:34:43.324838Z",
     "iopub.status.idle": "2021-12-02T20:34:43.341713Z",
     "shell.execute_reply": "2021-12-02T20:34:43.340990Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.325361Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the version numbers are unique and we don't really care about them, so might as well just remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.343529Z",
     "iopub.status.busy": "2021-12-02T20:34:43.343111Z",
     "iopub.status.idle": "2021-12-02T20:34:43.422236Z",
     "shell.execute_reply": "2021-12-02T20:34:43.421525Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.343479Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = train['family_accession'].apply(lambda x: x.split('.')[0])\n",
    "validation_labels = dev['family_accession'].apply(lambda x: x.split('.')[0])\n",
    "test_labels = test['family_accession'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If we have a new protein, we don't have the sequence alignment to the family, since we don't know the family, we are trying to find it! So it'd be cheating to use the aligned sequences, hence we just use the sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.424053Z",
     "iopub.status.busy": "2021-12-02T20:34:43.423608Z",
     "iopub.status.idle": "2021-12-02T20:34:43.489212Z",
     "shell.execute_reply": "2021-12-02T20:34:43.488468Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.424005Z"
    }
   },
   "outputs": [],
   "source": [
    "train_seq = train['sequence']\n",
    "dev_seq = dev['sequence']\n",
    "test_seq = test['sequence']\n",
    "\n",
    "del train, test, dev\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's get the pooled embeddings for each sequence (non-pooled would be more interesting but results in memory error in Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T20:34:43.491975Z",
     "iopub.status.busy": "2021-12-02T20:34:43.491515Z",
     "iopub.status.idle": "2021-12-02T21:17:22.832700Z",
     "shell.execute_reply": "2021-12-02T21:17:22.831909Z",
     "shell.execute_reply.started": "2021-12-02T20:34:43.491797Z"
    }
   },
   "outputs": [],
   "source": [
    "TAPEncoded_train = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader_train):\n",
    "        b = batch.to(torch.long)\n",
    "        output = modelTAPE(b.to(device))[1] #1 for pooled, 0 for all amino acids in peptide encoded\n",
    "        TAPEncoded_train.append(output.cpu().detach().numpy())\n",
    "        torch.cuda.empty_cache() \n",
    "        del b, output\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:17:22.834673Z",
     "iopub.status.busy": "2021-12-02T21:17:22.834098Z",
     "iopub.status.idle": "2021-12-02T21:17:22.838977Z",
     "shell.execute_reply": "2021-12-02T21:17:22.838156Z",
     "shell.execute_reply.started": "2021-12-02T21:17:22.834602Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# path = \"./\" + \"TAPEncoded_train_pooled\" + \".pickle\"\n",
    "# output = open(path, 'w+b')\n",
    "# pickle.dump(TAPEncoded_train, output)\n",
    "# output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For validation (dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:17:22.840886Z",
     "iopub.status.busy": "2021-12-02T21:17:22.840318Z",
     "iopub.status.idle": "2021-12-02T21:22:37.200722Z",
     "shell.execute_reply": "2021-12-02T21:22:37.199887Z",
     "shell.execute_reply.started": "2021-12-02T21:17:22.840831Z"
    }
   },
   "outputs": [],
   "source": [
    "TAPEncoded_val = []\n",
    "for batch in tqdm(dataloader_validation):\n",
    "    b = batch.to(torch.long)\n",
    "    output = modelTAPE(b.to(device))[1]\n",
    "    TAPEncoded_val.append(output.cpu().detach().numpy())\n",
    "    torch.cuda.empty_cache() \n",
    "    del b, output\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:22:37.202601Z",
     "iopub.status.busy": "2021-12-02T21:22:37.202340Z",
     "iopub.status.idle": "2021-12-02T21:27:52.694235Z",
     "shell.execute_reply": "2021-12-02T21:27:52.693259Z",
     "shell.execute_reply.started": "2021-12-02T21:22:37.202551Z"
    }
   },
   "outputs": [],
   "source": [
    "TAPEncoded_test = []\n",
    "for batch in tqdm(dataloader_test):\n",
    "    b = batch.to(torch.long)\n",
    "    output = modelTAPE(b.to(device))[1]\n",
    "    TAPEncoded_test.append(output.cpu().detach().numpy())\n",
    "    torch.cuda.empty_cache() \n",
    "    del b, output\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's merge the batches for train/dev/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:27:52.696784Z",
     "iopub.status.busy": "2021-12-02T21:27:52.696304Z",
     "iopub.status.idle": "2021-12-02T21:35:25.163666Z",
     "shell.execute_reply": "2021-12-02T21:35:25.162962Z",
     "shell.execute_reply.started": "2021-12-02T21:27:52.696544Z"
    }
   },
   "outputs": [],
   "source": [
    "train_encoded = np.array(TAPEncoded_train[0])\n",
    "for t in tqdm(TAPEncoded_train[1:]):\n",
    "    train_encoded = np.concatenate([train_encoded,t], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:35:25.165356Z",
     "iopub.status.busy": "2021-12-02T21:35:25.164917Z",
     "iopub.status.idle": "2021-12-02T21:35:26.267201Z",
     "shell.execute_reply": "2021-12-02T21:35:26.266574Z",
     "shell.execute_reply.started": "2021-12-02T21:35:25.165150Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_encoded = np.array(TAPEncoded_val[0])\n",
    "for t in tqdm(TAPEncoded_val[1:]):\n",
    "    dev_encoded = np.concatenate([dev_encoded,t], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:35:26.269019Z",
     "iopub.status.busy": "2021-12-02T21:35:26.268565Z",
     "iopub.status.idle": "2021-12-02T21:35:27.481423Z",
     "shell.execute_reply": "2021-12-02T21:35:27.480539Z",
     "shell.execute_reply.started": "2021-12-02T21:35:26.268851Z"
    }
   },
   "outputs": [],
   "source": [
    "test_encoded = np.array(TAPEncoded_test[0])\n",
    "for t in tqdm(TAPEncoded_test[1:]):\n",
    "    test_encoded = np.concatenate([test_encoded,t], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final dev shape, embedding is in a 768-long vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:35:27.484438Z",
     "iopub.status.busy": "2021-12-02T21:35:27.483815Z",
     "iopub.status.idle": "2021-12-02T21:35:27.491221Z",
     "shell.execute_reply": "2021-12-02T21:35:27.489932Z",
     "shell.execute_reply.started": "2021-12-02T21:35:27.484382Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled BERT Embedding + Dense Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's put a DNN on top to classify (just one layer, so really it's just logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:35:27.493474Z",
     "iopub.status.busy": "2021-12-02T21:35:27.492959Z",
     "iopub.status.idle": "2021-12-02T21:35:30.608341Z",
     "shell.execute_reply": "2021-12-02T21:35:30.607660Z",
     "shell.execute_reply.started": "2021-12-02T21:35:27.493202Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "label_tokenizer = Tokenizer(oov_token = -1)\n",
    "label_tokenizer.fit_on_texts(train_labels)\n",
    "\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
    "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))\n",
    "test_label_seq = np.array(label_tokenizer.texts_to_sequences(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:35:30.610009Z",
     "iopub.status.busy": "2021-12-02T21:35:30.609718Z",
     "iopub.status.idle": "2021-12-02T21:35:30.618467Z",
     "shell.execute_reply": "2021-12-02T21:35:30.617864Z",
     "shell.execute_reply.started": "2021-12-02T21:35:30.609965Z"
    }
   },
   "outputs": [],
   "source": [
    "numclass = len(np.unique(training_label_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining labels from zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:35:30.620473Z",
     "iopub.status.busy": "2021-12-02T21:35:30.620027Z",
     "iopub.status.idle": "2021-12-02T21:35:30.624957Z",
     "shell.execute_reply": "2021-12-02T21:35:30.624253Z",
     "shell.execute_reply.started": "2021-12-02T21:35:30.620308Z"
    }
   },
   "outputs": [],
   "source": [
    "#labels should be 1 to num_classes, otherwise loss will be nan: https://github.com/keras-team/keras/issues/1244\n",
    "training_label_seq = training_label_seq-1\n",
    "validation_label_seq = validation_label_seq-1\n",
    "test_label_seq = test_label_seq-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:35:30.626643Z",
     "iopub.status.busy": "2021-12-02T21:35:30.626144Z",
     "iopub.status.idle": "2021-12-02T21:35:30.724791Z",
     "shell.execute_reply": "2021-12-02T21:35:30.723637Z",
     "shell.execute_reply.started": "2021-12-02T21:35:30.626594Z"
    }
   },
   "outputs": [],
   "source": [
    "del train_labels, validation_labels, test_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model architecture - going simple, the hard work should've been done by the BERT encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T23:41:38.764575Z",
     "iopub.status.busy": "2021-12-02T23:41:38.764271Z",
     "iopub.status.idle": "2021-12-02T23:41:38.889062Z",
     "shell.execute_reply": "2021-12-02T23:41:38.887704Z",
     "shell.execute_reply.started": "2021-12-02T23:41:38.764523Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input_x = tf.keras.layers.Input(shape=(768,)) #768 is the embedding dimension\n",
    "out = tf.keras.layers.Dense(numclass+1, activation=\"softmax\")(input_x) #if you don't add 1, loss will be nan: https://github.com/keras-team/keras/issues/1244\n",
    "model = tf.keras.Model(inputs=input_x, outputs=out)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We use a learning rate scheduler and early stopping\n",
    "The 95% validation accuracy is quite nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T23:41:43.821986Z",
     "iopub.status.busy": "2021-12-02T23:41:43.821670Z",
     "iopub.status.idle": "2021-12-02T23:51:06.068712Z",
     "shell.execute_reply": "2021-12-02T23:51:06.067968Z",
     "shell.execute_reply.started": "2021-12-02T23:41:43.821935Z"
    }
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', min_delta=0.01, patience=5)\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(-epoch / 100))\n",
    "history = model.fit(train_encoded, \n",
    "                    training_label_seq, \n",
    "                    epochs=100, \n",
    "                    validation_data=(dev_encoded, validation_label_seq), \n",
    "                    verbose=2, \n",
    "                    callbacks=[es, lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T23:52:23.606676Z",
     "iopub.status.busy": "2021-12-02T23:52:23.606344Z",
     "iopub.status.idle": "2021-12-02T23:52:24.326344Z",
     "shell.execute_reply": "2021-12-02T23:52:24.325551Z",
     "shell.execute_reply.started": "2021-12-02T23:52:23.606615Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Taking the class with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T23:52:25.624248Z",
     "iopub.status.busy": "2021-12-02T23:52:25.623971Z",
     "iopub.status.idle": "2021-12-02T23:52:25.629695Z",
     "shell.execute_reply": "2021-12-02T23:52:25.628912Z",
     "shell.execute_reply.started": "2021-12-02T23:52:25.624200Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(preds,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final metric: testing accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T23:52:27.797203Z",
     "iopub.status.busy": "2021-12-02T23:52:27.796916Z",
     "iopub.status.idle": "2021-12-02T23:52:27.843816Z",
     "shell.execute_reply": "2021-12-02T23:52:27.843032Z",
     "shell.execute_reply.started": "2021-12-02T23:52:27.797153Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(preds==test_label_seq.T[0])/len(test_label_seq)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding + Residual Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's try our own method from scratch that doesn't rely on BERT and is quicker and see if we can get similar testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:37.898275Z",
     "iopub.status.busy": "2021-12-02T21:43:37.897706Z",
     "iopub.status.idle": "2021-12-02T21:43:38.696464Z",
     "shell.execute_reply": "2021-12-02T21:43:38.695756Z",
     "shell.execute_reply.started": "2021-12-02T21:43:37.897969Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sentences = train_seq.apply(lambda seq: [aa for aa in seq])\n",
    "validation_sentences = dev_seq.apply(lambda seq: [aa for aa in seq])\n",
    "test_sentences = test_seq.apply(lambda seq: [aa for aa in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:38.697987Z",
     "iopub.status.busy": "2021-12-02T21:43:38.697683Z",
     "iopub.status.idle": "2021-12-02T21:43:38.702225Z",
     "shell.execute_reply": "2021-12-02T21:43:38.701426Z",
     "shell.execute_reply.started": "2021-12-02T21:43:38.697941Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use tensorflow's tokenizer and sequence padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:38.703936Z",
     "iopub.status.busy": "2021-12-02T21:43:38.703443Z",
     "iopub.status.idle": "2021-12-02T21:43:55.899546Z",
     "shell.execute_reply": "2021-12-02T21:43:55.898743Z",
     "shell.execute_reply.started": "2021-12-02T21:43:38.703879Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "vocab_size = 25\n",
    "embedding_dim = vocab_size\n",
    "max_length = 512\n",
    "trunc_type = \"post\"\n",
    "padding_type = \"post\"\n",
    "oov_tok = \"<OOV>\"\n",
    "training_portion = .8\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=oov_tok, num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type)\n",
    "\n",
    "validation_sequences = tokenizer.texts_to_sequences(validation_sentences)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:55.900983Z",
     "iopub.status.busy": "2021-12-02T21:43:55.900697Z",
     "iopub.status.idle": "2021-12-02T21:43:56.082319Z",
     "shell.execute_reply": "2021-12-02T21:43:56.081727Z",
     "shell.execute_reply.started": "2021-12-02T21:43:55.900939Z"
    }
   },
   "outputs": [],
   "source": [
    "del train_sentences, train_sequences, validation_sentences, validation_sequences, test_sentences, test_sequences\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train/dev/test shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:56.083784Z",
     "iopub.status.busy": "2021-12-02T21:43:56.083511Z",
     "iopub.status.idle": "2021-12-02T21:43:56.090090Z",
     "shell.execute_reply": "2021-12-02T21:43:56.089196Z",
     "shell.execute_reply.started": "2021-12-02T21:43:56.083724Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_padded.shape)\n",
    "print(validation_padded.shape)\n",
    "print(test_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's make the architecture similar to ProtCNN's (see paper above) because it outperformed HMMER\n",
    "\n",
    "Creating the residual blocks with dilution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:56.091845Z",
     "iopub.status.busy": "2021-12-02T21:43:56.091377Z",
     "iopub.status.idle": "2021-12-02T21:43:56.099362Z",
     "shell.execute_reply": "2021-12-02T21:43:56.098501Z",
     "shell.execute_reply.started": "2021-12-02T21:43:56.091792Z"
    }
   },
   "outputs": [],
   "source": [
    "def residual_block(x, dil, filters):\n",
    "    shortcut = x\n",
    "    bn1 = tf.keras.layers.BatchNormalization()(x)\n",
    "    a1 = tf.keras.layers.Activation(\"relu\")(bn1)\n",
    "    conv1 = tf.keras.layers.Conv1D(filters, 3, dilation_rate = dil, padding=\"same\")(a1) #1100 filters and 31 kernel size in ProtCNN\n",
    "    \n",
    "    bn2 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    a2 = tf.keras.layers.Activation(\"relu\")(bn2)\n",
    "    conv2 = tf.keras.layers.Conv1D(filters, 1, padding=\"same\")(a2)\n",
    "    \n",
    "    x = tf.keras.layers.Add()([conv2, shortcut])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:56.101182Z",
     "iopub.status.busy": "2021-12-02T21:43:56.100707Z",
     "iopub.status.idle": "2021-12-02T21:43:56.108981Z",
     "shell.execute_reply": "2021-12-02T21:43:56.108243Z",
     "shell.execute_reply.started": "2021-12-02T21:43:56.101123Z"
    }
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', min_delta=0.01, patience=5)\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(-epoch / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:56.112829Z",
     "iopub.status.busy": "2021-12-02T21:43:56.112586Z",
     "iopub.status.idle": "2021-12-02T21:43:56.119053Z",
     "shell.execute_reply": "2021-12-02T21:43:56.118111Z",
     "shell.execute_reply.started": "2021-12-02T21:43:56.112773Z"
    }
   },
   "outputs": [],
   "source": [
    "# # detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# # instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relatively complex architecture containing 1D as well as 2D convolutions and skip connection (Residual Net)\n",
    "\n",
    "- One-hot encoding for the amino acids\n",
    "- First 1D Convolution along amino acids to capture if the same amino acid is nearby\n",
    "- 1D convolution along ebedding dimension to check which amino acids are recurring close to each other\n",
    "- Residual blocks to include possible skips\n",
    "- 2D convolution to finish it off to combine resulting embedding dimension along the sequence\n",
    "- Pooling and flattening and finally a Dense layer for multiclass classification\n",
    "- Note: 2D Conv layer was added for fun, is not in ProtCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T23:52:38.925382Z",
     "iopub.status.busy": "2021-12-02T23:52:38.924967Z",
     "iopub.status.idle": "2021-12-02T23:52:40.043397Z",
     "shell.execute_reply": "2021-12-02T23:52:40.042550Z",
     "shell.execute_reply.started": "2021-12-02T23:52:38.925310Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiating the model in the strategy scope creates the model on the TPU\n",
    "# with tpu_strategy.scope():\n",
    "input_x = tf.keras.layers.Input(shape=(512,))\n",
    "#will run out of memory if to_categorical is used, so need to one-hot encode here\n",
    "x = tf.keras.layers.Embedding(vocab_size, vocab_size, embeddings_initializer=tf.keras.initializers.Identity(gain=1.0), trainable=False)(input_x)\n",
    "x = tf.keras.layers.Permute(dims=[2, 1])(x)\n",
    "x = tf.keras.layers.Conv1D(64, 8, padding=\"same\")(x)\n",
    "x = residual_block(x, 1, 64)\n",
    "x = residual_block(x, 2, 64)\n",
    "x = tf.keras.layers.Permute(dims=[2, 1])(x)\n",
    "x = tf.keras.layers.Conv1D(64, 3, padding=\"same\")(x)\n",
    "x = residual_block(x, 1, 64)\n",
    "x = residual_block(x, 2, 64) #4 blocks of these in ProtCNN\n",
    "x = tf.keras.layers.Lambda(lambda x: K.expand_dims(x, -1))(x) #will not compile if not defined as lambda\n",
    "x = tf.keras.layers.Conv2D(32, (4,4), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(8, (8,8), padding=\"same\")(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D((64,64))(x)\n",
    "#x = tf.keras.layers.Conv1D(8, 8, padding=\"same\")(x)\n",
    "#x = tf.keras.layers.MaxPooling1D(64)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "out = tf.keras.layers.Dense(numclass+1, activation=\"softmax\")(x) #if you don't add 1, loss will be nan: https://github.com/keras-team/keras/issues/1244\n",
    "\n",
    "model = tf.keras.Model(inputs=input_x, outputs=out)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-5) #0.001 default learning rate was too large and learning was stuck\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:56.982093Z",
     "iopub.status.busy": "2021-12-02T21:43:56.981832Z",
     "iopub.status.idle": "2021-12-02T21:43:56.991999Z",
     "shell.execute_reply": "2021-12-02T21:43:56.990926Z",
     "shell.execute_reply.started": "2021-12-02T21:43:56.982048Z"
    }
   },
   "outputs": [],
   "source": [
    "# with tpu_strategy.scope():\n",
    "#     input_x = tf.keras.layers.Input(shape=(512,))\n",
    "#     x = tf.keras.layers.Embedding(vocab_size, vocab_size, embeddings_initializer=tf.keras.initializers.Identity(gain=1.0), trainable=False)(input_x)\n",
    "#     x = tf.keras.layers.LSTM(64, return_sequences=True)(x)\n",
    "    \n",
    "#     x = tf.keras.layers.LSTM(64)(x)\n",
    "#     out = tf.keras.layers.Dense(numclass, activation=\"softmax\")(x)\n",
    "#     model2 = tf.keras.Model(inputs=input_x, outputs=out)\n",
    "#     model2.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "# model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T21:43:56.993616Z",
     "iopub.status.busy": "2021-12-02T21:43:56.993352Z",
     "iopub.status.idle": "2021-12-02T21:43:57.002184Z",
     "shell.execute_reply": "2021-12-02T21:43:57.000939Z",
     "shell.execute_reply.started": "2021-12-02T21:43:56.993570Z"
    }
   },
   "outputs": [],
   "source": [
    "# history2 = model2.fit(train_padded, \n",
    "#                       training_label_seq, \n",
    "#                       epochs=100, \n",
    "#                       validation_data=(validation_padded, validation_label_seq), \n",
    "#                       callbacks = [lr_schedule],\n",
    "#                       verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Again, we got around 95% accuracy on dev set!\n",
    "- Likely could be made better by avoiding the slight overfitting via regularization/dropout/model complexity reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T23:52:41.912617Z",
     "iopub.status.busy": "2021-12-02T23:52:41.912327Z",
     "iopub.status.idle": "2021-12-03T00:05:56.685434Z",
     "shell.execute_reply": "2021-12-03T00:05:56.684772Z",
     "shell.execute_reply.started": "2021-12-02T23:52:41.912564Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_padded, \n",
    "                    training_label_seq, \n",
    "                    epochs=100, \n",
    "                    validation_data=(validation_padded, validation_label_seq), \n",
    "                    callbacks = [es,lr_schedule], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T00:09:02.463678Z",
     "iopub.status.busy": "2021-12-03T00:09:02.463371Z",
     "iopub.status.idle": "2021-12-03T00:09:04.774475Z",
     "shell.execute_reply": "2021-12-03T00:09:04.773714Z",
     "shell.execute_reply.started": "2021-12-03T00:09:02.463617Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T00:09:07.088715Z",
     "iopub.status.busy": "2021-12-03T00:09:07.088435Z",
     "iopub.status.idle": "2021-12-03T00:09:07.094209Z",
     "shell.execute_reply": "2021-12-03T00:09:07.093380Z",
     "shell.execute_reply.started": "2021-12-03T00:09:07.088665Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(preds,axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final metric: testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T00:09:11.518376Z",
     "iopub.status.busy": "2021-12-03T00:09:11.518080Z",
     "iopub.status.idle": "2021-12-03T00:09:11.562550Z",
     "shell.execute_reply": "2021-12-03T00:09:11.561711Z",
     "shell.execute_reply.started": "2021-12-03T00:09:11.518326Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(preds==test_label_seq.T[0])/len(test_label_seq)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In conclusion we got around 95% accuracy on 100 similarly-sized classes from scratch which is pretty amazing! We used two different methods, and could've done a lot of others, for example:\n",
    "- HMMER\n",
    "- LSTM\n",
    "- k-NN in embedding dimension\n",
    "- k-NN with Levenshtein distance\n",
    "- BERT embedding for each amino acid (not pooled) and then ProtCNN (ResNet) layer on top instead of just DNN\n",
    "- Ensemble of models\n",
    "-..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
